{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g-ilYZUtIAp"
      },
      "source": [
        "#### Load the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RUHzH56esEge"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torchvision.models as models\n",
        "\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3HA65UktLOS"
      },
      "source": [
        "#### Dataset download & load / EfficientNet_B2 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cEjb32-atI-9"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Define the root path to the train and test folders\n",
        "root_folder = '/content/drive/MyDrive/korea_influencer/'\n",
        "\n",
        "# Define subfolder paths\n",
        "train_folder = os.path.join(root_folder, 'train')\n",
        "test_folder = os.path.join(root_folder, 'test')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "\n",
        "    transforms.RandomResizedCrop(size=(256, 256), scale=(0.5, 1.0), ratio=(3 / 4, 4 / 3)),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.5, 0.5, 0.5],\n",
        "        std=[0.5, 0.5, 0.5]\n",
        "    )\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.5, 0.5, 0.5],\n",
        "        std=[0.5, 0.5, 0.5]\n",
        "    )\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.5, 0.5, 0.5],\n",
        "        std=[0.5, 0.5, 0.5]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Create custom datasets using the ImageFolder dataset class\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_folder, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root=test_folder, transform=transform_test)\n",
        "\n",
        "#train / val 9:1\n",
        "dataset_size = len(train_dataset)\n",
        "train_size = int(dataset_size * 0.9)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "train_dataset_jin, val_dataset_jin = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Set batch sizes and create data loaders\n",
        "batch_size_train = 10\n",
        "batch_size_val = 10\n",
        "batch_size_test = 10\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset_jin, batch_size=batch_size_train, shuffle=True, num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset_jin, batch_size=batch_size_val, shuffle=False, num_workers = 4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8jcaDqk2tJg"
      },
      "source": [
        "# Data visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "qXVpW4ct2vAJ",
        "outputId": "958e604a-804c-45e6-cfcb-d5f57efddcb8"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [30, 8]\n",
        "plt.rcParams['figure.dpi'] = 60\n",
        "plt.rcParams.update({'font.size': 20})\n",
        "\n",
        "\n",
        "def imshow(input):\n",
        "    # torch.Tensor => numpy\n",
        "    input = input.numpy().transpose((1, 2, 0))\n",
        "    # undo image normalization\n",
        "    mean = np.array([0.5, 0.5, 0.5])\n",
        "    std = np.array([0.5, 0.5, 0.5])\n",
        "    input = std * input + mean\n",
        "    input = np.clip(input, 0, 1)\n",
        "    # display images\n",
        "    plt.imshow(input)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class_names = {\n",
        "  0: \"IU\",\n",
        "  1: \"kimyouna\",\n",
        "  2: \"ive_JWY\",\n",
        "  3: \"bts_jimin\",\n",
        "  4: \"kangdaniel\",\n",
        "  5: \"bts_V\",\n",
        "  6: \"astro_CEW\",\n",
        "  7: \"rv_irene\",\n",
        "  8: \"aespa_karina\",\n",
        "  9: \"stkiz_hyunjin\",\n",
        "  10: \"njs_haerin\",\n",
        "  11: \"bp_jisoo\",\n",
        "  12: \"ive_ahnyoojin\",\n",
        "  13: \"rv_joy\",\n",
        "  14: \"lesse_sakura\",\n",
        "  15: \"bts_jungkook\",\n",
        "  16: \"bp_jennie\",\n",
        "  17: \"shinee_minho\",\n",
        "  18: \"idle_minnie\",\n",
        "  19: \"idle_yuqi\",\n",
        "  20: \"idel_miyeon\",\n",
        "  21: \"gg_taeyoun\",\n",
        "  22: \"gg_yuna\",\n",
        "  23: \"shinee_key\",\n",
        "  24: \"shinee_taemin\",\n",
        "  25: \"btob_yooksungjae\",\n",
        "  26: \"kimsoohyun\",\n",
        "  27: \"hyunbin\",\n",
        "  28: \"10cm\",\n",
        "  29: \"ive_gaeul\",\n",
        "  30: \"kimtaeri\",\n",
        "  31: \"leedongyook\",\n",
        "  32: \"lesse_kimchaewon\",\n",
        "  33: \"namjuhyuk\",\n",
        "  34: \"nct_mark\",\n",
        "  35: \"gongyoo\",\n",
        "  36: \"kangdongwon\",\n",
        "  37: \"lesse_kazuha\",\n",
        "  38: \"songjungki\",\n",
        "  39: \"aespa_winter\",\n",
        "  40: \"twice_tzuwi\",\n",
        "  41: \"idle_shuhwa\",\n",
        "  42: \"parkhaejin\",\n",
        "  43: \"paulkim\",\n",
        "  44: \"ahnbohyun\",\n",
        "  45: \"aespa_ningning\",\n",
        "  46: \"itzy_yezi\",\n",
        "  47: \"newist_minhyun\",\n",
        "  48: \"ahnhyosub\",\n",
        "  49: \"bp_rose\"\n",
        "}\n",
        "\n",
        "# load a batch of train image\n",
        "iterator = iter(train_loader)\n",
        "\n",
        "# visualize a batch of train image\n",
        "imgs, labels = next(iterator)\n",
        "out = torchvision.utils.make_grid(imgs[:6])\n",
        "imshow(out)\n",
        "print([class_names[labels[i].item()] for i in range(6)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZG6NpCstO20"
      },
      "source": [
        "#### Training & Testing settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu1HtdSuB7go",
        "outputId": "7fbf616d-c7c1-470c-8dbd-28c79a2125c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.002\n",
        "log_step = 20\n",
        "n_classes = 50\n",
        "\n",
        "model = models.efficientnet_b2(pretrained=True)\n",
        "num_features = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_features, n_classes) # transfer learning\n",
        "model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6HVkpY6jB8SA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def train():\n",
        "    start_time = time.time()\n",
        "    print(f'[Epoch: {epoch + 1} - Training]')\n",
        "    model.train()\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        optimizer.zero_grad()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += labels.shape[0]\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        if i % log_step == log_step - 1:\n",
        "            print(f'[Batch: {i + 1}] running train loss: {running_loss / total}, running train accuracy: {running_corrects / total}')\n",
        "\n",
        "    print(f'train loss: {running_loss / total}, accuracy: {running_corrects / total}')\n",
        "    print(\"elapsed time:\", time.time() - start_time)\n",
        "    return running_loss / total, (running_corrects / total).item()\n",
        "\n",
        "\n",
        "def validate():\n",
        "    start_time = time.time()\n",
        "    print(f'[Epoch: {epoch + 1} - Validation]')\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for i, batch in enumerate(val_loader):\n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        total += labels.shape[0]\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        if (i == 0) or (i % log_step == log_step - 1):\n",
        "            print(f'[Batch: {i + 1}] running val loss: {running_loss / total}, running val accuracy: {running_corrects / total}')\n",
        "\n",
        "    print(f'val loss: {running_loss / total}, accuracy: {running_corrects / total}')\n",
        "    print(\"elapsed time:\", time.time() - start_time)\n",
        "    return running_loss / total, (running_corrects / total).item()\n",
        "\n",
        "\n",
        "def test():\n",
        "    start_time = time.time()\n",
        "    print(f'[Test]')\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for i, batch in enumerate(test_loader):\n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        total += labels.shape[0]\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        if (i == 0) or (i % log_step == log_step - 1):\n",
        "            print(f'[Batch: {i + 1}] running test loss: {running_loss / total}, running test accuracy: {running_corrects / total}')\n",
        "\n",
        "    print(f'test loss: {running_loss / total}, accuracy: {running_corrects / total}')\n",
        "    print(\"elapsed time:\", time.time() - start_time)\n",
        "    return running_loss / total, (running_corrects / total).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeydlCGFCVA-",
        "outputId": "7e28291a-4e5c-4724-ad76-dab857bf41ab"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = learning_rate\n",
        "    if epoch >= 5:\n",
        "        lr /= 10\n",
        "    if epoch >= 10:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "num_epochs = 25\n",
        "best_val_acc = 0\n",
        "best_epoch = 0\n",
        "\n",
        "history = []\n",
        "accuracy = []\n",
        "for epoch in range(num_epochs):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train_loss, train_acc = train()\n",
        "    val_loss, val_acc = validate()\n",
        "    history.append((train_loss, val_loss))\n",
        "    accuracy.append((train_acc, val_acc))\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        print(\"[Info] best validation accuracy!\")\n",
        "        best_val_acc = val_acc\n",
        "        best_epoch = epoch\n",
        "        torch.save(model.state_dict(), f'best_checkpoint_epoch_{epoch + 1}.pth')\n",
        "\n",
        "torch.save(model.state_dict(), f'EfficientNet_B2_best_epoch.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "PMk5uYP2DEHp",
        "outputId": "1b820012-5e3e-41d2-c066-b61445e9c9e0"
      },
      "outputs": [],
      "source": [
        "plt.plot([x[0] for x in history], 'b', label='train')\n",
        "plt.plot([x[1] for x in history], 'r--',label='validation')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "btTXsGr7DEBi",
        "outputId": "4fcf3bd1-980c-4266-b6ce-a76ed63fc67c"
      },
      "outputs": [],
      "source": [
        "plt.plot([x[0] for x in accuracy], 'b', label='train')\n",
        "plt.plot([x[1] for x in accuracy], 'r--',label='validation')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KhTTEazDD6N",
        "outputId": "7b5b7263-739f-48db-ce10-1a1f8748c7d9"
      },
      "outputs": [],
      "source": [
        "model = models.efficientnet_b2(pretrained=True)\n",
        "num_features = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_features, n_classes) # transfer learning\n",
        "model = model.cuda()\n",
        "model_path = 'EfficientNet_B2_best_epoch.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "test_loss, test_accuracy = test()\n",
        "print(f\"Test loss: {test_loss:.8f}\")\n",
        "print(f\"Test accuracy: {test_accuracy * 100.:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
