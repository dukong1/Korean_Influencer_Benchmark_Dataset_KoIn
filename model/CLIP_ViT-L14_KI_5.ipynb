{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXTH7bcTpxcF",
        "outputId": "f6426892-e550-4d62-cb55-56838cb3aea1"
      },
      "outputs": [],
      "source": [
        "!pip install ftfy regex tqdm\n",
        "# Install CLIP library\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UNyIop-npM1O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchvision.models as models\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "import clip\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from pkg_resources import packaging\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(clip.available_models())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DNeIO4Z5PZr",
        "outputId": "86432721-f1f7-49cb-f793-d72ca4911c4a"
      },
      "outputs": [],
      "source": [
        "# Load the CLIP model with the specified architecture \"ViT-L/14\"\n",
        "model, preprocess = clip.load(\"ViT-L/14\")\n",
        "model.cuda().eval()\n",
        "input_resolution = model.visual.input_resolution\n",
        "context_length = model.context_length\n",
        "vocab_size = model.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjew7SL23DKI",
        "outputId": "4466afbd-8998-4406-ea5d-53ecb20657f0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load('ViT-L/14', device)\n",
        "\n",
        "# Define the root path to the train and test folders\n",
        "root_folder = '/content/drive/MyDrive/korea_influencer/'\n",
        "\n",
        "# Define subfolder paths\n",
        "train_folder = os.path.join(root_folder, 'KI_tiny_5')\n",
        "test_folder = os.path.join(root_folder, 'test')\n",
        "\n",
        "train = torchvision.datasets.ImageFolder(root=train_folder, transform=preprocess)\n",
        "test = torchvision.datasets.ImageFolder(root=test_folder, transform=preprocess)\n",
        "\n",
        "def get_features(dataset):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(DataLoader(dataset, batch_size=100)):\n",
        "            features = model.encode_image(images.to(device))\n",
        "\n",
        "            all_features.append(features)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n",
        "\n",
        "# Calculate the image features\n",
        "train_features, train_labels = get_features(train)\n",
        "test_features, test_labels = get_features(test)\n",
        "\n",
        "# Perform logistic regression\n",
        "classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\n",
        "classifier.fit(train_features, train_labels)\n",
        "\n",
        "# Evaluate using the logistic regression classifier\n",
        "predictions = classifier.predict(test_features)\n",
        "accuracy = np.mean((test_labels == predictions).astype(float)) * 100.\n",
        "print(f\"Accuracy = {accuracy:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
